{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e36fca",
   "metadata": {},
   "source": [
    "# Comprensi√≥n y An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "**Proyecto:** Pipeline MLOps - Predicci√≥n de Pago a Tiempo de Cr√©ditos\n",
    "\n",
    "**Autor:** Alexis Jacquet\n",
    "\n",
    "**Fecha:** 5 de febrero de 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Realizar un an√°lisis exploratorio exhaustivo de los datos para:\n",
    "1. Comprender la estructura y caracter√≠sticas de los datos\n",
    "2. Identificar patrones, tendencias y anomal√≠as\n",
    "3. Detectar problemas de calidad de datos\n",
    "4. Establecer reglas de validaci√≥n\n",
    "5. Identificar transformaciones necesarias para el modelado\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. Carga de Datos y Configuraci√≥n\n",
    "2. Exploraci√≥n Inicial de Datos\n",
    "3. An√°lisis Univariable\n",
    "4. An√°lisis Bivariable\n",
    "5. An√°lisis Multivariable\n",
    "6. Reglas de Validaci√≥n\n",
    "7. Transformaciones Identificadas\n",
    "8. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b24c12",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, pearsonr, spearmanr\n",
    "\n",
    "# Configuraci√≥n\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Librer√≠as cargadas y configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "RUTA_RAIZ = Path.cwd().parent.parent\n",
    "RUTA_DATOS = RUTA_RAIZ / 'Base_de_datos.csv'\n",
    "\n",
    "df = pd.read_csv(RUTA_DATOS)\n",
    "print(f\"‚úì Datos cargados: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
    "\n",
    "# Crear una copia para trabajar sin modificar el original\n",
    "df_original = df.copy()\n",
    "print(\"‚úì Copia de seguridad creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894b021",
   "metadata": {},
   "source": [
    "## 2. Exploraci√≥n Inicial de Datos\n",
    "\n",
    "### 2.1 Descripci√≥n General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"INFORMACI√ìN GENERAL DEL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDimensiones: {df.shape[0]:,} registros x {df.shape[1]} variables\")\n",
    "print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa de los datos\n",
    "print(\"Primeras 10 filas del dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c67b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n detallada de columnas\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438624b",
   "metadata": {},
   "source": [
    "### 2.2 Caracterizaci√≥n de Variables\n",
    "\n",
    "Clasificaremos las variables seg√∫n su tipo y naturaleza para un an√°lisis m√°s estructurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de variables\n",
    "columnas_numericas = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "columnas_categoricas = df.select_dtypes(include=['object']).columns.tolist()\n",
    "columnas_fecha = [col for col in df.columns if 'fecha' in col.lower()]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Pago_atiempo'\n",
    "\n",
    "# Eliminar variable objetivo y fechas de las listas\n",
    "if variable_objetivo in columnas_numericas:\n",
    "    columnas_numericas.remove(variable_objetivo)\n",
    "for fecha in columnas_fecha:\n",
    "    if fecha in columnas_numericas:\n",
    "        columnas_numericas.remove(fecha)\n",
    "    if fecha in columnas_categoricas:\n",
    "        columnas_categoricas.remove(fecha)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CARACTERIZACI√ìN DE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä VARIABLE OBJETIVO:\")\n",
    "print(f\"   {variable_objetivo}\")\n",
    "print(f\"\\nüî¢ VARIABLES NUM√âRICAS ({len(columnas_numericas)}):\")\n",
    "for i, col in enumerate(columnas_numericas, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "print(f\"\\nüìù VARIABLES CATEG√ìRICAS ({len(columnas_categoricas)}):\")\n",
    "for i, col in enumerate(columnas_categoricas, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "print(f\"\\nüìÖ VARIABLES DE FECHA ({len(columnas_fecha)}):\")\n",
    "for i, col in enumerate(columnas_fecha, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038e815",
   "metadata": {},
   "source": [
    "### 2.3 An√°lisis de Valores Nulos\n",
    "\n",
    "Identificaremos y cuantificaremos los valores nulos en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis detallado de valores nulos\n",
    "def analizar_nulos(dataframe):\n",
    "    \"\"\"\n",
    "    Analiza valores nulos en el dataframe\n",
    "    \"\"\"\n",
    "    nulos_count = dataframe.isnull().sum()\n",
    "    nulos_pct = (nulos_count / len(dataframe)) * 100\n",
    "    \n",
    "    resumen = pd.DataFrame({\n",
    "        'Columna': dataframe.columns,\n",
    "        'Tipo_Dato': dataframe.dtypes,\n",
    "        'Valores_Nulos': nulos_count.values,\n",
    "        'Porcentaje_Nulos': nulos_pct.values,\n",
    "        'Valores_Unicos': [dataframe[col].nunique() for col in dataframe.columns]\n",
    "    })\n",
    "    \n",
    "    resumen = resumen.sort_values('Valores_Nulos', ascending=False)\n",
    "    return resumen\n",
    "\n",
    "resumen_nulos = analizar_nulos(df)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE VALORES NULOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de valores nulos en el dataset: {df.isnull().sum().sum():,}\")\n",
    "print(f\"Porcentaje total de nulos: {(df.isnull().sum().sum() / df.size * 100):.2f}%\\n\")\n",
    "\n",
    "# Mostrar solo columnas con nulos\n",
    "resumen_con_nulos = resumen_nulos[resumen_nulos['Valores_Nulos'] > 0]\n",
    "\n",
    "if len(resumen_con_nulos) > 0:\n",
    "    print(f\"\\nColumnas con valores nulos: {len(resumen_con_nulos)}\\n\")\n",
    "    print(resumen_con_nulos.to_string(index=False))\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    if len(resumen_con_nulos) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(resumen_con_nulos['Columna'], resumen_con_nulos['Porcentaje_Nulos'], \n",
    "                color='coral', edgecolor='black')\n",
    "        plt.xlabel('Porcentaje de Valores Nulos (%)', fontsize=11)\n",
    "        plt.title('Distribuci√≥n de Valores Nulos por Columna', fontsize=13, fontweight='bold')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"\\n‚úì No se encontraron valores nulos en ninguna columna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c116f",
   "metadata": {},
   "source": [
    "### 2.4 Unificar Representaci√≥n de Valores Nulos\n",
    "\n",
    "Convertiremos diferentes representaciones de nulos a un formato est√°ndar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1084245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores que deben considerarse como nulos\n",
    "valores_nulos = ['', ' ', 'NA', 'N/A', 'na', 'n/a', 'NULL', 'null', 'None', 'none', '-', '--', '?']\n",
    "\n",
    "print(\"Unificando representaciones de valores nulos...\")\n",
    "print(f\"\\nValores tratados como nulos: {valores_nulos}\")\n",
    "\n",
    "# Reemplazar valores nulos en columnas categ√≥ricas\n",
    "for col in columnas_categoricas:\n",
    "    df[col] = df[col].replace(valores_nulos, np.nan)\n",
    "\n",
    "# Verificar cambios\n",
    "nulos_despues = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal de nulos despu√©s de unificar: {nulos_despues:,}\")\n",
    "print(\"‚úì Valores nulos unificados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301a8a9",
   "metadata": {},
   "source": [
    "### 2.5 Conversi√≥n de Tipos de Datos\n",
    "\n",
    "Aseguraremos que cada columna tenga el tipo de dato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONVERSI√ìN DE TIPOS DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convertir columnas de fecha\n",
    "for col in columnas_fecha:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            print(f\"‚úì {col} convertida a datetime\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al convertir {col}: {str(e)}\")\n",
    "\n",
    "# Verificar y convertir variable objetivo a entero\n",
    "if variable_objetivo in df.columns:\n",
    "    df[variable_objetivo] = df[variable_objetivo].astype(int)\n",
    "    print(f\"‚úì {variable_objetivo} confirmada como int\")\n",
    "\n",
    "# Variables categ√≥ricas que podr√≠an ser booleanas o nominales\n",
    "# tipo_credito: parece ser categ√≥rica ordinal o nominal\n",
    "# tipo_laboral: categ√≥rica nominal\n",
    "# tendencia_ingresos: categ√≥rica ordinal\n",
    "\n",
    "print(\"\\nTipos de datos actualizados:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb6a93",
   "metadata": {},
   "source": [
    "### 2.6 Identificaci√≥n de Variables Irrelevantes\n",
    "\n",
    "Analizaremos si existen variables que no aportan informaci√≥n al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE VARIABLES IRRELEVANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "variables_baja_varianza = []\n",
    "variables_muchos_nulos = []\n",
    "variables_constantes = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Variables con un solo valor √∫nico (constantes)\n",
    "    if df[col].nunique() == 1:\n",
    "        variables_constantes.append(col)\n",
    "    \n",
    "    # Variables con m√°s del 90% de nulos\n",
    "    pct_nulos = (df[col].isnull().sum() / len(df)) * 100\n",
    "    if pct_nulos > 90:\n",
    "        variables_muchos_nulos.append(col)\n",
    "    \n",
    "    # Variables con muy baja varianza (>95% mismo valor para categ√≥ricas)\n",
    "    if col in columnas_categoricas:\n",
    "        if df[col].value_counts(normalize=True).iloc[0] > 0.95:\n",
    "            variables_baja_varianza.append(col)\n",
    "\n",
    "print(f\"\\nVariables constantes (1 valor √∫nico): {len(variables_constantes)}\")\n",
    "if variables_constantes:\n",
    "    print(f\"   {variables_constantes}\")\n",
    "\n",
    "print(f\"\\nVariables con >90% nulos: {len(variables_muchos_nulos)}\")\n",
    "if variables_muchos_nulos:\n",
    "    print(f\"   {variables_muchos_nulos}\")\n",
    "\n",
    "print(f\"\\nVariables con baja varianza (>95% mismo valor): {len(variables_baja_varianza)}\")\n",
    "if variables_baja_varianza:\n",
    "    for var in variables_baja_varianza:\n",
    "        print(f\"   - {var}: {df[var].value_counts(normalize=True).iloc[0]*100:.1f}% es '{df[var].value_counts().index[0]}'\")\n",
    "\n",
    "variables_a_eliminar = list(set(variables_constantes + variables_muchos_nulos))\n",
    "\n",
    "if len(variables_a_eliminar) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Se recomienda eliminar {len(variables_a_eliminar)} variables\")\n",
    "    print(f\"    Variables: {variables_a_eliminar}\")\n",
    "else:\n",
    "    print(\"\\n‚úì No se identificaron variables claramente irrelevantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fef1c7",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Univariable\n",
    "\n",
    "### 3.1 Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas completas para variables num√©ricas\n",
    "print(\"=\"*80)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS\")\n",
    "print(\"=\"*80)\n",
    "df[columnas_numericas].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas adicionales: skewness, kurtosis\n",
    "print(\"=\"*80)\n",
    "print(\"MEDIDAS DE FORMA DE DISTRIBUCI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "estadisticas_forma = pd.DataFrame({\n",
    "    'Variable': columnas_numericas,\n",
    "    'Skewness': [df[col].skew() for col in columnas_numericas],\n",
    "    'Kurtosis': [df[col].kurtosis() for col in columnas_numericas]\n",
    "})\n",
    "\n",
    "# Interpretaci√≥n de skewness\n",
    "estadisticas_forma['Interpretacion_Skewness'] = estadisticas_forma['Skewness'].apply(\n",
    "    lambda x: 'Sim√©trica' if abs(x) < 0.5 else ('Asim√©trica derecha' if x > 0 else 'Asim√©trica izquierda')\n",
    ")\n",
    "\n",
    "print(estadisticas_forma.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n: Histogramas y boxplots para variables num√©ricas\n",
    "def plot_distribucion_numerica(df, columnas, filas=4, columnas_grafico=3):\n",
    "    \"\"\"\n",
    "    Crea histogramas y boxplots para variables num√©ricas\n",
    "    \"\"\"\n",
    "    n_cols = len(columnas)\n",
    "    n_filas = (n_cols // columnas_grafico) + (1 if n_cols % columnas_grafico > 0 else 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_filas, columnas_grafico, figsize=(18, n_filas * 4))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(columnas):\n",
    "        # Histograma con KDE\n",
    "        axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7, density=True)\n",
    "        df[col].dropna().plot(kind='kde', ax=axes[idx], color='red', linewidth=2)\n",
    "        axes[idx].set_title(f'Distribuci√≥n: {col}', fontweight='bold')\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Ocultar ejes vac√≠os\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Distribuciones de Variables Num√©ricas:\")\n",
    "plot_distribucion_numerica(df, columnas_numericas[:9])  # Primeras 9 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuar con m√°s variables si hay m√°s de 9\n",
    "if len(columnas_numericas) > 9:\n",
    "    plot_distribucion_numerica(df, columnas_numericas[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para detectar outliers\n",
    "def plot_boxplots(df, columnas, filas=4, columnas_grafico=3):\n",
    "    \"\"\"\n",
    "    Crea boxplots para variables num√©ricas\n",
    "    \"\"\"\n",
    "    n_cols = len(columnas)\n",
    "    n_filas = (n_cols // columnas_grafico) + (1 if n_cols % columnas_grafico > 0 else 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_filas, columnas_grafico, figsize=(18, n_filas * 3))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(columnas):\n",
    "        axes[idx].boxplot(df[col].dropna(), vert=True)\n",
    "        axes[idx].set_title(f'Boxplot: {col}', fontweight='bold')\n",
    "        axes[idx].set_ylabel(col)\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Ocultar ejes vac√≠os\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nBoxplots para Detecci√≥n de Outliers:\")\n",
    "plot_boxplots(df, columnas_numericas[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941bb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(columnas_numericas) > 9:\n",
    "    plot_boxplots(df, columnas_numericas[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196454a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de outliers usando IQR\n",
    "def analizar_outliers(df, columnas):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el m√©todo IQR\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for col in columnas:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[col] < limite_inferior) | (df[col] > limite_superior)][col]\n",
    "        \n",
    "        resultados.append({\n",
    "            'Variable': col,\n",
    "            'Q1': Q1,\n",
    "            'Q3': Q3,\n",
    "            'IQR': IQR,\n",
    "            'Limite_Inferior': limite_inferior,\n",
    "            'Limite_Superior': limite_superior,\n",
    "            'N_Outliers': len(outliers),\n",
    "            'Porcentaje_Outliers': (len(outliers) / len(df)) * 100\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE OUTLIERS (M√âTODO IQR)\")\n",
    "print(\"=\"*80)\n",
    "outliers_df = analizar_outliers(df, columnas_numericas)\n",
    "print(outliers_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebdfc8",
   "metadata": {},
   "source": [
    "### 3.2 Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89356ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas para variables categ√≥ricas\n",
    "print(\"=\"*80)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES CATEG√ìRICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in columnas_categoricas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Variable: {col}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Valores √∫nicos: {df[col].nunique()}\")\n",
    "    print(f\"Valor m√°s frecuente: {df[col].mode()[0] if len(df[col].mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"\\nDistribuci√≥n de frecuencias:\")\n",
    "    \n",
    "    frecuencias = df[col].value_counts()\n",
    "    frecuencias_pct = df[col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    resumen = pd.DataFrame({\n",
    "        'Frecuencia': frecuencias,\n",
    "        'Porcentaje': frecuencias_pct\n",
    "    })\n",
    "    \n",
    "    print(resumen.head(10))  # Mostrar top 10 categor√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de variables categ√≥ricas\n",
    "def plot_categoricas(df, columnas):\n",
    "    \"\"\"\n",
    "    Crea gr√°ficos de barras para variables categ√≥ricas\n",
    "    \"\"\"\n",
    "    for col in columnas:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Countplot\n",
    "        value_counts = df[col].value_counts()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts.plot(kind='bar', edgecolor='black', alpha=0.7)\n",
    "        plt.title(f'Distribuci√≥n: {col}', fontweight='bold', fontsize=12)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Pie chart\n",
    "        plt.subplot(1, 2, 2)\n",
    "        if len(value_counts) <= 10:  # Solo si hay pocas categor√≠as\n",
    "            plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.title(f'Proporci√≥n: {col}', fontweight='bold', fontsize=12)\n",
    "        else:\n",
    "            top10 = value_counts.head(10)\n",
    "            plt.pie(top10, labels=top10.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.title(f'Proporci√≥n (Top 10): {col}', fontweight='bold', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Distribuciones de Variables Categ√≥ricas:\")\n",
    "plot_categoricas(df, columnas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfac403",
   "metadata": {},
   "source": [
    "## 4. An√°lisis Bivariable\n",
    "\n",
    "### 4.1 Relaci√≥n con la Variable Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c141c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE LA VARIABLE OBJETIVO: Pago_atiempo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "distribucion_objetivo = df[variable_objetivo].value_counts().sort_index()\n",
    "distribucion_pct = df[variable_objetivo].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(f\"\\nDistribuci√≥n:\")\n",
    "print(f\"  Clase 0 (No pag√≥ a tiempo): {distribucion_objetivo[0]:,} ({distribucion_pct[0]:.2f}%)\")\n",
    "print(f\"  Clase 1 (Pag√≥ a tiempo): {distribucion_objetivo[1]:,} ({distribucion_pct[1]:.2f}%)\")\n",
    "\n",
    "ratio = min(distribucion_objetivo) / max(distribucion_objetivo)\n",
    "print(f\"\\nRatio de balance: {ratio:.3f}\")\n",
    "\n",
    "if ratio < 0.5:\n",
    "    print(\"‚ö†Ô∏è  Dataset desbalanceado - Considerar t√©cnicas de balanceo\")\n",
    "else:\n",
    "    print(\"‚úì Dataset razonablemente balanceado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables num√©ricas vs Variable objetivo\n",
    "def analizar_numerica_vs_objetivo(df, columnas_num, var_objetivo):\n",
    "    \"\"\"\n",
    "    Analiza la relaci√≥n entre variables num√©ricas y la variable objetivo\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for col in columnas_num:\n",
    "        # Estad√≠sticas por clase\n",
    "        clase_0 = df[df[var_objetivo] == 0][col]\n",
    "        clase_1 = df[df[var_objetivo] == 1][col]\n",
    "        \n",
    "        # Test estad√≠stico (t-test)\n",
    "        try:\n",
    "            t_stat, p_value = stats.ttest_ind(clase_0.dropna(), clase_1.dropna())\n",
    "        except:\n",
    "            t_stat, p_value = np.nan, np.nan\n",
    "        \n",
    "        resultados.append({\n",
    "            'Variable': col,\n",
    "            'Media_Clase_0': clase_0.mean(),\n",
    "            'Media_Clase_1': clase_1.mean(),\n",
    "            'Mediana_Clase_0': clase_0.median(),\n",
    "            'Mediana_Clase_1': clase_1.median(),\n",
    "            'Diferencia_Medias': abs(clase_0.mean() - clase_1.mean()),\n",
    "            'p_value': p_value,\n",
    "            'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados).sort_values('p_value')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS BIVARIABLE: VARIABLES NUM√âRICAS VS OBJETIVO\")\n",
    "print(\"=\"*80)\n",
    "analisis_num_objetivo = analizar_numerica_vs_objetivo(df, columnas_numericas, variable_objetivo)\n",
    "print(analisis_num_objetivo.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n: Boxplots por clase objetivo\n",
    "def plot_boxplots_por_clase(df, columnas_num, var_objetivo, n_vars=6):\n",
    "    \"\"\"\n",
    "    Crea boxplots comparando distribuciones por clase objetivo\n",
    "    \"\"\"\n",
    "    # Seleccionar variables m√°s significativas\n",
    "    vars_significativas = analisis_num_objetivo.head(n_vars)['Variable'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(vars_significativas):\n",
    "        df.boxplot(column=col, by=var_objetivo, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{col} por Pago_atiempo', fontweight='bold')\n",
    "        axes[idx].set_xlabel('Pago a tiempo')\n",
    "        axes[idx].set_ylabel(col)\n",
    "        plt.sca(axes[idx])\n",
    "        plt.xticks([1, 2], ['No (0)', 'S√≠ (1)'])\n",
    "    \n",
    "    plt.suptitle('')  # Eliminar t√≠tulo autom√°tico de pandas\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nBoxplots de Variables M√°s Significativas por Clase:\")\n",
    "plot_boxplots_por_clase(df, columnas_numericas, variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categ√≥ricas vs Variable objetivo\n",
    "def analizar_categorica_vs_objetivo(df, columnas_cat, var_objetivo):\n",
    "    \"\"\"\n",
    "    Analiza la relaci√≥n entre variables categ√≥ricas y la variable objetivo\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for col in columnas_cat:\n",
    "        # Tabla de contingencia\n",
    "        tabla_contingencia = pd.crosstab(df[col], df[var_objetivo])\n",
    "        \n",
    "        # Test Chi-cuadrado\n",
    "        try:\n",
    "            chi2, p_value, dof, expected = chi2_contingency(tabla_contingencia)\n",
    "        except:\n",
    "            chi2, p_value = np.nan, np.nan\n",
    "        \n",
    "        # Cram√©r's V (medida de asociaci√≥n)\n",
    "        n = tabla_contingencia.sum().sum()\n",
    "        cramers_v = np.sqrt(chi2 / (n * (min(tabla_contingencia.shape) - 1))) if not np.isnan(chi2) else np.nan\n",
    "        \n",
    "        resultados.append({\n",
    "            'Variable': col,\n",
    "            'Categorias_Unicas': df[col].nunique(),\n",
    "            'Chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'Cramers_V': cramers_v,\n",
    "            'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados).sort_values('p_value')\n",
    "\n",
    "if len(columnas_categoricas) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AN√ÅLISIS BIVARIABLE: VARIABLES CATEG√ìRICAS VS OBJETIVO\")\n",
    "    print(\"=\"*80)\n",
    "    analisis_cat_objetivo = analizar_categorica_vs_objetivo(df, columnas_categoricas, variable_objetivo)\n",
    "    print(analisis_cat_objetivo.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n: Gr√°ficos de barras agrupadas\n",
    "if len(columnas_categoricas) > 0:\n",
    "    for col in columnas_categoricas:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Tabla de contingencia normalizada\n",
    "        tabla = pd.crosstab(df[col], df[variable_objetivo], normalize='index') * 100\n",
    "        \n",
    "        tabla.plot(kind='bar', stacked=False, edgecolor='black', alpha=0.7)\n",
    "        plt.title(f'{col} vs Pago_atiempo', fontweight='bold', fontsize=13)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Porcentaje (%)')\n",
    "        plt.legend(['No pag√≥ (0)', 'Pag√≥ (1)'], title='Pago a tiempo')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddfadd",
   "metadata": {},
   "source": [
    "## 5. An√°lisis Multivariable\n",
    "\n",
    "### 5.1 Matriz de Correlaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d220f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de correlaci√≥n\n",
    "print(\"=\"*80)\n",
    "print(\"MATRIZ DE CORRELACI√ìN - VARIABLES NUM√âRICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Incluir variable objetivo en la correlaci√≥n\n",
    "cols_para_corr = columnas_numericas + [variable_objetivo]\n",
    "correlacion = df[cols_para_corr].corr()\n",
    "\n",
    "# Visualizaci√≥n de la matriz de correlaci√≥n\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(correlacion, dtype=bool))  # M√°scara para tri√°ngulo superior\n",
    "sns.heatmap(correlacion, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci√≥n de Variables Num√©ricas', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar correlaciones fuertes\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELACIONES FUERTES (|r| > 0.7)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Obtener correlaciones significativas (excluyendo diagonal)\n",
    "correlaciones_fuertes = []\n",
    "for i in range(len(correlacion.columns)):\n",
    "    for j in range(i+1, len(correlacion.columns)):\n",
    "        if abs(correlacion.iloc[i, j]) > 0.7:\n",
    "            correlaciones_fuertes.append({\n",
    "                'Variable_1': correlacion.columns[i],\n",
    "                'Variable_2': correlacion.columns[j],\n",
    "                'Correlacion': correlacion.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if correlaciones_fuertes:\n",
    "    df_corr_fuertes = pd.DataFrame(correlaciones_fuertes).sort_values('Correlacion', \n",
    "                                                                        key=abs, ascending=False)\n",
    "    print(df_corr_fuertes.to_string(index=False))\n",
    "    print(\"\\n‚ö†Ô∏è  Advertencia: Variables con correlaci√≥n muy alta pueden causar multicolinealidad\")\n",
    "else:\n",
    "    print(\"No se encontraron correlaciones fuertes (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaci√≥n con la variable objetivo\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELACI√ìN CON LA VARIABLE OBJETIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlacion_objetivo = correlacion[variable_objetivo].drop(variable_objetivo).sort_values(\n",
    "    key=abs, ascending=False\n",
    ")\n",
    "\n",
    "print(correlacion_objetivo)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlacion_objetivo.plot(kind='barh', color=['green' if x > 0 else 'red' for x in correlacion_objetivo],\n",
    "                          edgecolor='black', alpha=0.7)\n",
    "plt.title('Correlaci√≥n de Variables con Pago_atiempo', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Coeficiente de Correlaci√≥n')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6318e",
   "metadata": {},
   "source": [
    "### 5.2 Pairplot de Variables Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece458c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las 5 variables m√°s correlacionadas con el objetivo\n",
    "top_vars = correlacion_objetivo.head(5).index.tolist()\n",
    "cols_pairplot = top_vars + [variable_objetivo]\n",
    "\n",
    "print(f\"Creando pairplot con las variables m√°s relevantes: {top_vars}\")\n",
    "print(\"Esto puede tomar unos momentos...\")\n",
    "\n",
    "# Crear pairplot\n",
    "sns.pairplot(df[cols_pairplot], hue=variable_objetivo, diag_kind='kde', \n",
    "             plot_kws={'alpha': 0.6}, height=2.5)\n",
    "plt.suptitle('Pairplot de Variables M√°s Correlacionadas con Pago_atiempo', \n",
    "             y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63702e01",
   "metadata": {},
   "source": [
    "## 6. Reglas de Validaci√≥n de Datos\n",
    "\n",
    "Bas√°ndonos en el EDA, establecemos reglas de validaci√≥n para el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baee541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"REGLAS DE VALIDACI√ìN DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "reglas_validacion = {\n",
    "    'tipo_credito': {\n",
    "        'tipo': 'int',\n",
    "        'rango': (df['tipo_credito'].min(), df['tipo_credito'].max()),\n",
    "        'permite_nulos': False\n",
    "    },\n",
    "    'fecha_prestamo': {\n",
    "        'tipo': 'datetime',\n",
    "        'rango': (df['fecha_prestamo'].min(), df['fecha_prestamo'].max()),\n",
    "        'permite_nulos': False\n",
    "    },\n",
    "    'capital_prestado': {\n",
    "        'tipo': 'float',\n",
    "        'rango': (0, df['capital_prestado'].quantile(0.99)),\n",
    "        'permite_nulos': True\n",
    "    },\n",
    "    'plazo_meses': {\n",
    "        'tipo': 'int',\n",
    "        'rango': (1, 360),\n",
    "        'permite_nulos': False\n",
    "    },\n",
    "    'edad_cliente': {\n",
    "        'tipo': 'int',\n",
    "        'rango': (18, 100),\n",
    "        'permite_nulos': False\n",
    "    },\n",
    "    'tipo_laboral': {\n",
    "        'tipo': 'str',\n",
    "        'valores_validos': df['tipo_laboral'].dropna().unique().tolist(),\n",
    "        'permite_nulos': True\n",
    "    },\n",
    "    'salario_cliente': {\n",
    "        'tipo': 'int',\n",
    "        'rango': (0, df['salario_cliente'].quantile(0.99)),\n",
    "        'permite_nulos': False\n",
    "    },\n",
    "    'Pago_atiempo': {\n",
    "        'tipo': 'int',\n",
    "        'valores_validos': [0, 1],\n",
    "        'permite_nulos': False\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nReglas de validaci√≥n definidas:\")\n",
    "for variable, reglas in reglas_validacion.items():\n",
    "    print(f\"\\n{variable}:\")\n",
    "    for regla, valor in reglas.items():\n",
    "        print(f\"  - {regla}: {valor}\")\n",
    "\n",
    "print(\"\\n‚úì Reglas de validaci√≥n establecidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1e527",
   "metadata": {},
   "source": [
    "## 7. Transformaciones Identificadas\n",
    "\n",
    "Documentamos las transformaciones necesarias para la fase de Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRANSFORMACIONES IDENTIFICADAS PARA FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "transformaciones = {\n",
    "    '1. Tratamiento de Nulos': [\n",
    "        f\"- tendencia_ingresos: {df['tendencia_ingresos'].isnull().sum()} nulos -> Imputar con moda o categor√≠a 'Desconocido'\",\n",
    "        f\"- puntaje: {df['puntaje'].isnull().sum()} nulos -> Imputar con mediana o media\",\n",
    "        f\"- capital_prestado: {df['capital_prestado'].isnull().sum()} nulos -> Imputar con mediana\"\n",
    "    ],\n",
    "    '2. Encoding de Variables Categ√≥ricas': [\n",
    "        \"- tipo_laboral: One-Hot Encoding o Label Encoding\",\n",
    "        \"- tendencia_ingresos: Ordinal Encoding (Decreciente < Estable < Creciente)\"\n",
    "    ],\n",
    "    '3. Escalado de Variables Num√©ricas': [\n",
    "        \"- Aplicar StandardScaler o MinMaxScaler a todas las variables num√©ricas\",\n",
    "        \"- Considerar RobustScaler para variables con outliers\"\n",
    "    ],\n",
    "    '4. Feature Engineering': [\n",
    "        \"- Crear 'ratio_cuota_salario': cuota_pactada / salario_cliente\",\n",
    "        \"- Crear 'total_deuda': saldo_total + saldo_mora\",\n",
    "        \"- Crear 'antiguedad_credito': d√≠as desde fecha_prestamo\",\n",
    "        \"- Crear 'ratio_otros_prestamos': total_otros_prestamos / salario_cliente\",\n",
    "        \"- Binning de edad_cliente en grupos etarios\"\n",
    "    ],\n",
    "    '5. Tratamiento de Outliers': [\n",
    "        \"- Aplicar Winsorization o Capping en variables con outliers extremos\",\n",
    "        \"- Considerar transformaciones logar√≠tmicas para variables asim√©tricas\"\n",
    "    ],\n",
    "    '6. Balanceo de Clases': [\n",
    "        f\"- Ratio actual: {ratio:.3f}\",\n",
    "        \"- T√©cnicas recomendadas: SMOTE, RandomUnderSampler o Class Weight\"\n",
    "    ] if ratio < 0.7 else [\"- No es cr√≠tico balancear (ratio aceptable)\"]\n",
    "}\n",
    "\n",
    "for categoria, items in transformaciones.items():\n",
    "    print(f\"\\n{categoria}\")\n",
    "    for item in items:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff64dd3",
   "metadata": {},
   "source": [
    "## 8. Conclusiones y Recomendaciones\n",
    "\n",
    "### 8.1 Resumen de Hallazgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONCLUSIONES DEL AN√ÅLISIS EXPLORATORIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "conclusiones = f\"\"\"\n",
    "üìä RESUMEN DEL DATASET:\n",
    "- Total de registros: {df.shape[0]:,}\n",
    "- Variables num√©ricas: {len(columnas_numericas)}\n",
    "- Variables categ√≥ricas: {len(columnas_categoricas)}\n",
    "- Variables de fecha: {len(columnas_fecha)}\n",
    "- Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
    "\n",
    "üéØ VARIABLE OBJETIVO:\n",
    "- Distribuci√≥n: Clase 0 ({distribucion_pct[0]:.1f}%), Clase 1 ({distribucion_pct[1]:.1f}%)\n",
    "- Balance: {'Desbalanceado' if ratio < 0.5 else 'Aceptable'} (ratio: {ratio:.3f})\n",
    "\n",
    "‚ùì CALIDAD DE DATOS:\n",
    "- Total de nulos: {df.isnull().sum().sum():,} ({(df.isnull().sum().sum() / df.size * 100):.2f}%)\n",
    "- Columnas con nulos: {len(resumen_con_nulos)}\n",
    "- Variables a eliminar: {len(variables_a_eliminar)}\n",
    "\n",
    "üîç INSIGHTS PRINCIPALES:\n",
    "1. Variables m√°s correlacionadas con Pago_atiempo:\n",
    "{chr(10).join([f'   - {var}: {correlacion_objetivo[var]:.3f}' for var in correlacion_objetivo.head(5).index])}\n",
    "\n",
    "2. Outliers detectados:\n",
    "{chr(10).join([f'   - {row[\"Variable\"]}: {row[\"N_Outliers\"]} outliers ({row[\"Porcentaje_Outliers\"]:.1f}%)' for _, row in outliers_df.nlargest(3, 'N_Outliers').iterrows()])}\n",
    "\n",
    "3. Variables con alta correlaci√≥n entre s√≠:\n",
    "{chr(10).join([f'   - {row[\"Variable_1\"]} ‚Üî {row[\"Variable_2\"]}: {row[\"Correlacion\"]:.3f}' for _, row in df_corr_fuertes.head(3).iterrows()]) if correlaciones_fuertes else '   - No se detectaron correlaciones excesivamente altas'}\n",
    "\n",
    "‚úÖ RECOMENDACIONES:\n",
    "1. Implementar pipeline robusto de limpieza de datos\n",
    "2. Aplicar t√©cnicas de imputaci√≥n para valores nulos\n",
    "3. Realizar feature engineering seg√∫n transformaciones identificadas\n",
    "4. Considerar balanceo de clases durante el entrenamiento\n",
    "5. Implementar validaci√≥n de datos seg√∫n reglas establecidas\n",
    "6. Monitorear drift de datos en producci√≥n\n",
    "\n",
    "‚úì Dataset listo para la fase de Feature Engineering\n",
    "\"\"\"\n",
    "\n",
    "print(conclusiones)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc519a",
   "metadata": {},
   "source": [
    "### 8.2 Exportar Resumen del EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resumen del EDA en archivo de texto\n",
    "ruta_resumen = RUTA_RAIZ / 'eda_resumen.txt'\n",
    "\n",
    "with open(ruta_resumen, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"RESUMEN DEL AN√ÅLISIS EXPLORATORIO DE DATOS\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(conclusiones)\n",
    "    f.write(\"\\n\\nREGLAS DE VALIDACI√ìN:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for variable, reglas in reglas_validacion.items():\n",
    "        f.write(f\"\\n{variable}:\\n\")\n",
    "        for regla, valor in reglas.items():\n",
    "            f.write(f\"  - {regla}: {valor}\\n\")\n",
    "\n",
    "print(f\"‚úì Resumen del EDA guardado en: {ruta_resumen}\")\n",
    "print(\"\\n‚úì An√°lisis Exploratorio completado exitosamente\")\n",
    "print(\"\\nüìç Siguiente paso: Feature Engineering (ft_engineering.py)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
