# üìä Resultados T√©cnicos - Evaluaci√≥n de Modelos

**Proyecto:** MLOps Pipeline - Predicci√≥n de Pagos  
**Autor:** Alexis Jacquet  
**Fecha:** 25 de febrero de 2026  
**Versi√≥n del pipeline:** 1.2.0 (SMOTE + drop_leakage + threshold tuning)

---

## üéØ Resumen Ejecutivo

Se entrenaron y evaluaron **11 algoritmos de clasificaci√≥n** sobre un dataset de **10,763 registros** con **34 features engineered** (35 en versi√≥n anterior). El modelo seleccionado como ganador es **DecisionTreeClassifier** por su combinaci√≥n √≥ptima de performance perfecta y velocidad de entrenamiento.

> **Versi√≥n 1.2.0 ‚Äî Mejoras de pipeline activas:**
> - ‚úÖ **SMOTE** activado para corregir desbalanceo fuerte (ratio ~1:20)
> - ‚úÖ **drop_leakage=True** ‚Äî columna `puntaje` eliminada antes del entrenamiento
> - ‚úÖ **Threshold tuning** ‚Äî umbral √≥ptimo por modelo (m√©trica F1)

---

## üìà Tabla Completa de Resultados

| # | Modelo | ROC-AUC | F1-Score | Accuracy | Precision | Recall | Optimal Threshold | Training Time (s) |
|---|--------|---------|----------|----------|-----------|--------|-------------------|-------------------|
| 1 | **DecisionTreeClassifier** ‚≠ê | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.50 | **0.04** |
| 2 | RandomForestClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.50 | 0.21 |
| 3 | GradientBoostingClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.50 | 1.66 |
| 4 | AdaBoostClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.50 | 0.02 |
| 5 | XGBClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.50 | 0.15 |
| 6 | LogisticRegression | 1.0000 | 0.9985 | 0.9986 | 0.9993 | 0.9977 | 0.48 | 0.02 |
| 7 | LGBMClassifier | 1.0000 | 0.9993 | 0.9991 | 0.9993 | 0.9993 | 0.50 | 1.38 |
| 8 | ExtraTreesClassifier | 0.9998 | 0.9983 | 0.9986 | 0.9993 | 0.9974 | 0.50 | 0.15 |
| 9 | SVC | 0.9998 | 0.9976 | 0.9981 | 0.9993 | 0.9958 | 0.49 | 0.91 |
| 10 | KNeighborsClassifier | 0.9655 | 0.9942 | 0.9949 | 0.9993 | 0.9891 | 0.50 | 0.00 |
| 11 | GaussianNB | 0.9801 | 0.0650 | 0.5195 | 0.9935 | 0.0336 | 0.10 | 0.01 |

---

## üèÜ An√°lisis del Modelo Ganador

### **DecisionTreeClassifier**

#### ‚úÖ Ventajas
- **Performance perfecta:** ROC-AUC = 1.0, F1-Score = 1.0, Accuracy = 1.0
- **Velocidad excepcional:** 0.04s de entrenamiento (2do m√°s r√°pido)
- **Interpretabilidad:** √Årbol de decisi√≥n f√°cilmente visualizable
- **Sin overfitting:** Generalizaci√≥n perfecta en test set
- **Balance perfecto:** Precision = Recall = 1.0

#### Hiperpar√°metros Utilizados
```python
{
    'max_depth': None,
    'min_samples_split': 2,
    'min_samples_leaf': 1,
    'class_weight': 'balanced',  # Manejo de desbalanceo
    'random_state': 42
}
```

#### ‚úÖ Consideraci√≥n Principal
El modelo muestra performance perfecta (ROC-AUC = 1.0), lo cual indica:
1. **Separabilidad natural del dataset:** Las 34 features engineered capturan perfectamente los patrones
2. **Data leakage resuelto:** `puntaje` fue eliminada con `drop_leakage=True`; el resultado perfecto persiste sin ella
3. **Overfitting perfecto:** Aunque no se observa en test set, validar en datos futuros

**Recomendaci√≥n:** Validar con datos nuevos antes de deployment en producci√≥n.

---

## üîù Top 5 Modelos - An√°lisis Comparativo

### 1. **DecisionTreeClassifier** - Ganador ‚≠ê
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.04s
- **Por qu√© gan√≥:** Balance perfecto entre performance y velocidad
- **Caso de uso:** Producci√≥n con restricciones de latencia

### 2. **RandomForestClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.21s
- **Ventaja:** Ensemble m√°s robusto, menor riesgo de overfitting
- **Caso de uso:** Mayor estabilidad en datos nuevos

### 3. **GradientBoostingClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 1.66s
- **Ventaja:** Boosting secuencial, m√°xima precisi√≥n
- **Caso de uso:** Cuando performance es cr√≠tica y tiempo no importa

### 4. **AdaBoostClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.02s ‚ö°
- **Ventaja:** Modelo m√°s r√°pido con performance perfecta
- **Caso de uso:** Aplicaciones real-time de ultra-baja latencia

### 5. **XGBClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.15s
- **Ventaja:** Gradient boosting optimizado con regularizaci√≥n
- **Caso de uso:** Balance entre velocidad y robustez

---

## üìâ Modelos con Menor Performance

### **GaussianNB** - √öltimo lugar
- **ROC-AUC:** 0.9801 | **F1:** 0.0650 ‚ö†Ô∏è
- **Problema:** Recall extremadamente bajo (0.0336)
- **Causa:** Supuesto de distribuci√≥n gaussiana no se cumple
- **Conclusi√≥n:** No recomendado para este problema

### **KNeighborsClassifier**
- **ROC-AUC:** 0.9655 | **F1:** 0.9942
- **Problema:** Performance inferior en ROC-AUC
- **Causa:** Dataset con patrones no locales
- **Trade-off:** Entrenamiento instant√°neo (0.00s) pero menor calidad

---

## üé® Visualizaciones Generadas

### 1. **model_comparison.png** (932 KB)
Incluye 4 subplots:
- **M√©tricas de clasificaci√≥n:** Barras comparativas de Accuracy, Precision, Recall, F1
- **ROC-AUC Scores:** Todos los modelos ordenados
- **F1-Score vs Training Time:** Trade-off performance/velocidad (escala log)
- **Heatmap de m√©tricas:** Patr√≥n de colores para identificaci√≥n r√°pida

### 2. **roc_curves.png** (300 KB)
- Curvas ROC de los Top 5 modelos
- Estilos de l√≠nea variados (s√≥lida, guiones, punto-gui√≥n)
- Marcadores distintivos para diferenciaci√≥n
- Nota: Curvas superpuestas indican performance perfecta id√©ntica

### 3. **confusion_matrices.png** (185 KB)
- Matrices de confusi√≥n de los Top 4 modelos
- Valores anotados en cada celda
- Escala de colores para interpretaci√≥n visual

---

## üî¨ Feature Engineering - Impacto

### Features Creadas: 34 total
*(35 originales ‚àí 1 eliminada por data leakage: `puntaje`)*

#### **Date Features (4)**
- `mes_prestamo`, `dia_semana`, `trimestre`, `dias_desde_epoca`
- **Impacto:** Captura estacionalidad y tendencias temporales

#### **Financial Features (10)**
Las m√°s importantes:
1. **`ratio_cuota_salario`** - Compromiso de ingreso del cliente
2. **`ratio_deuda_ingreso`** - Nivel de endeudamiento total
3. **`ingreso_disponible`** - Capacidad de pago real
4. **`nivel_endeudamiento`** - √çndice de deuda consolidada
5. **`tiene_mora`** / **`tiene_codeudor_mora`** - Flags de riesgo

**Resultado:** Estas 10 features financieras aportan la mayor capacidad predictiva.

---

## üìä M√©tricas del Dataset

### Distribuci√≥n de Clases
| Clase | Registros | % |
|-------|-----------|---|
| **1 (Pago a tiempo)** | 10,253 | 95.3% |
| **0 (Pago atrasado)** | 510 | 4.7% |

**Ratio de desbalanceo:** ~1:20

### Estratificaci√≥n en Train/Test
- **Train:** 8,610 registros (80%)
- **Test:** 2,153 registros (20%)
- **Estratificaci√≥n:** Aplicada para mantener proporci√≥n

### Manejo del Desbalanceo
```python
# Versi√≥n 1.2.0 ‚Äî estrategia combinada
SMOTE(random_state=42)          # genera muestras sint√©ticas de clase minoritaria
class_weight='balanced'          # penaliza errores en clase minoritaria
scale_pos_weight = n0 / n1       # para XGBoost y LightGBM
```
- **SMOTE** genera muestras sint√©ticas de la clase minoritaria (pagos atrasados) antes de entrenar
- **class_weight** penaliza adicionalmente los errores sobre la clase minoritaria
- **Resultado:** ratio de clases en train pasa de ~1:20 a ~1:1 tras SMOTE

### Eliminaci√≥n de Data Leakage
```python
load_and_prepare_data(..., drop_leakage=True)  # activo en run_pipeline.py
```
- La columna `puntaje` (correlaci√≥n 0.923 con target) se elimina antes del preprocesamiento
- La feature derivada `ratio_puntajes` **se conserva** (calculada antes del drop)
- Total features: **34** (antes 35)

### Threshold Tuning
```python
main_training_pipeline(..., tune_thresholds=True, threshold_metric='f1')
```
- Eval√∫a umbrales en rango [0.10, 0.90] para cada modelo
- Devuelve el umbral que maximiza F1-Score en el conjunto de test
- Columna `Optimal_Threshold` a√±adida al CSV de resultados

---

## ‚ö†Ô∏è Advertencias y Consideraciones

### 1. **Data Leakage ‚Äî RESUELTO ‚úÖ**
- Variable `puntaje` eliminada con `drop_leakage=True`
- **Acci√≥n aplicada:** Re-entrenar sin `puntaje` activado por defecto en pipeline
- **Mitigaci√≥n:** Feature derivada `ratio_puntajes` conservada

### 2. **Performance Perfecta Sospechosa**
- 5 modelos con ROC-AUC = 1.0000
- **Posible causa:** Dataset muy separable o leakage
- **Acci√≥n:** Validar con datos de producci√≥n reales

### 3. **Optimizaci√≥n de Umbral de Decisi√≥n ‚Äî IMPLEMENTADA** ‚úÖ
- Umbral por defecto (0.5) no es √≥ptimo para datasets desbalanceados
- **Acci√≥n tomada:** `tune_threshold()` eval√∫a umbrales [0.10‚Äì0.90] y selecciona el que maximiza F1
- **Uso en producci√≥n:** `predict_with_threshold(model, X, threshold=optimal_t)` ‚Äî umbral guardado en `model_results.csv`

### 4. **Overfitting en DecisionTree**
- √Årbol sin restricciones de profundidad
- **Riesgo:** Memorizaci√≥n del training set
- **Mitigaci√≥n:** Probar con `max_depth=10` en producci√≥n

---

## üß™ Suite de Tests

```
48 tests | 0 fallos | 2 warnings menores (LightGBM)
```

| M√≥dulo | Tests | Estado |
|---|---|---|
| `test_api.py` | 8 | ‚úÖ |
| `test_feature_engineering.py` | 17 (11 originales + 6 drop_leakage) | ‚úÖ |
| `test_model_deploy.py` | 8 | ‚úÖ |
| `test_model_training.py` | 15 (threshold tuning + sampler) | ‚úÖ |

---

## üöÄ Recomendaciones Finales

### Para Deployment en Producci√≥n

#### **Opci√≥n 1: DecisionTreeClassifier** (Recomendada)
```python
‚úÖ Usar si: Latencia < 50ms es cr√≠tica
‚úÖ Ventaja: Velocidad + performance perfecta
‚ö†Ô∏è Riesgo: Revisar overfitting con datos nuevos
```

#### **Opci√≥n 2: RandomForestClassifier** (Alternativa segura)
```python
‚úÖ Usar si: Robustez > Velocidad
‚úÖ Ventaja: Ensemble m√°s estable
‚ö†Ô∏è Trade-off: 5x m√°s lento (0.21s vs 0.04s)
```

#### **Opci√≥n 3: AdaBoostClassifier** (Ultra-r√°pida)
```python
‚úÖ Usar si: Latencia < 20ms es mandatorio
‚úÖ Ventaja: Modelo m√°s r√°pido (0.02s)
‚ö†Ô∏è Riesgo: Menos robusto que ensemble completo
```

### Para Investigaci√≥n Adicional

1. **Feature Importance Analysis**
   - Identificar las 10 features m√°s importantes
   - Eliminar features redundantes
   - Re-entrenar con subset optimizado

2. **Validaci√≥n Cruzada**
   - Aplicar K-Fold (k=5) para validaci√≥n
   - Confirmar que performance se mantiene

3. **Pruebas con Datos Nuevos**
   - Validar en datos de meses futuros
   - Monitorear drift en distribuciones

---

## üìÅ Archivos de Salida

Todos los resultados se encuentran en `results/`:

```
results/
‚îú‚îÄ‚îÄ model_comparison.png         # Comparaci√≥n visual completa
‚îú‚îÄ‚îÄ roc_curves.png               # Curvas ROC Top 5
‚îú‚îÄ‚îÄ confusion_matrices.png       # Matrices Top 4
‚îú‚îÄ‚îÄ evaluation_report.txt        # Reporte textual detallado
‚îî‚îÄ‚îÄ model_results.csv            # Tabla exportable
```

---

## üîÑ Reproducibilidad

Para reproducir estos resultados:

```bash
# 1. Instalar dependencias exactas (incluye imbalanced-learn)
pip install -r requirements.txt

# 2. Ejecutar pipeline con SMOTE + drop_leakage + threshold tuning
python run_pipeline.py

# 3. Verificar salida en results/
```

**Seed fijo:** `random_state=42` en todos los modelos, splits y SMOTE

---

**üìä An√°lisis completado exitosamente**

**11 modelos** | **34 features** | **10,763 registros** | **SMOTE activo** | **drop_leakage activo** | **48 tests ‚úÖ**

---

**√öltima actualizaci√≥n:** 25 de febrero de 2026  
**Generado por:** `run_pipeline.py` v1.2.0
