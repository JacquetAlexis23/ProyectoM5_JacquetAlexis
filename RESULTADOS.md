# üìä Resultados T√©cnicos - Evaluaci√≥n de Modelos

**Proyecto:** MLOps Pipeline - Predicci√≥n de Pagos  
**Autor:** Alexis Jacquet  
**Fecha:** 9 de febrero de 2026

---

## üéØ Resumen Ejecutivo

Se entrenaron y evaluaron **11 algoritmos de clasificaci√≥n** sobre un dataset de **10,763 registros** con **35 features engineered**. El modelo seleccionado como ganador es **DecisionTreeClassifier** por su combinaci√≥n √≥ptima de performance perfecta y velocidad de entrenamiento.

---

## üìà Tabla Completa de Resultados

| # | Modelo | ROC-AUC | F1-Score | Accuracy | Precision | Recall | Training Time (s) |
|---|--------|---------|----------|----------|-----------|--------|-------------------|
| 1 | **DecisionTreeClassifier** ‚≠ê | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | **0.04** |
| 2 | RandomForestClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.21 |
| 3 | GradientBoostingClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.66 |
| 4 | AdaBoostClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.02 |
| 5 | XGBClassifier | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.15 |
| 6 | LogisticRegression | 1.0000 | 0.9985 | 0.9986 | 0.9993 | 0.9977 | 0.02 |
| 7 | LGBMClassifier | 1.0000 | 0.9993 | 0.9991 | 0.9993 | 0.9993 | 1.38 |
| 8 | ExtraTreesClassifier | 0.9998 | 0.9983 | 0.9986 | 0.9993 | 0.9974 | 0.15 |
| 9 | SVC | 0.9998 | 0.9976 | 0.9981 | 0.9993 | 0.9958 | 0.91 |
| 10 | KNeighborsClassifier | 0.9655 | 0.9942 | 0.9949 | 0.9993 | 0.9891 | 0.00 |
| 11 | GaussianNB | 0.9801 | 0.0650 | 0.5195 | 0.9935 | 0.0336 | 0.01 |

---

## üèÜ An√°lisis del Modelo Ganador

### **DecisionTreeClassifier**

#### ‚úÖ Ventajas
- **Performance perfecta:** ROC-AUC = 1.0, F1-Score = 1.0, Accuracy = 1.0
- **Velocidad excepcional:** 0.04s de entrenamiento (2do m√°s r√°pido)
- **Interpretabilidad:** √Årbol de decisi√≥n f√°cilmente visualizable
- **Sin overfitting:** Generalizaci√≥n perfecta en test set
- **Balance perfecto:** Precision = Recall = 1.0

#### Hiperpar√°metros Utilizados
```python
{
    'max_depth': None,
    'min_samples_split': 2,
    'min_samples_leaf': 1,
    'class_weight': 'balanced',  # Manejo de desbalanceo
    'random_state': 42
}
```

#### ‚ö†Ô∏è Consideraci√≥n Principal
El modelo muestra performance perfecta (ROC-AUC = 1.0), lo cual puede indicar:
1. **Separabilidad natural del dataset:** Las 35 features engineered capturan perfectamente los patrones
2. **Posible data leakage:** La variable `puntaje` tiene correlaci√≥n 0.923 con el target (revisar en producci√≥n)
3. **Overfitting perfecto:** Aunque no se observa en test set, validar en datos futuros

**Recomendaci√≥n:** Validar con datos nuevos antes de deployment en producci√≥n.

---

## üîù Top 5 Modelos - An√°lisis Comparativo

### 1. **DecisionTreeClassifier** - Ganador ‚≠ê
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.04s
- **Por qu√© gan√≥:** Balance perfecto entre performance y velocidad
- **Caso de uso:** Producci√≥n con restricciones de latencia

### 2. **RandomForestClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.21s
- **Ventaja:** Ensemble m√°s robusto, menor riesgo de overfitting
- **Caso de uso:** Mayor estabilidad en datos nuevos

### 3. **GradientBoostingClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 1.66s
- **Ventaja:** Boosting secuencial, m√°xima precisi√≥n
- **Caso de uso:** Cuando performance es cr√≠tica y tiempo no importa

### 4. **AdaBoostClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.02s ‚ö°
- **Ventaja:** Modelo m√°s r√°pido con performance perfecta
- **Caso de uso:** Aplicaciones real-time de ultra-baja latencia

### 5. **XGBClassifier**
- **ROC-AUC:** 1.0000 | **F1:** 1.0000 | **Time:** 0.15s
- **Ventaja:** Gradient boosting optimizado con regularizaci√≥n
- **Caso de uso:** Balance entre velocidad y robustez

---

## üìâ Modelos con Menor Performance

### **GaussianNB** - √öltimo lugar
- **ROC-AUC:** 0.9801 | **F1:** 0.0650 ‚ö†Ô∏è
- **Problema:** Recall extremadamente bajo (0.0336)
- **Causa:** Supuesto de distribuci√≥n gaussiana no se cumple
- **Conclusi√≥n:** No recomendado para este problema

### **KNeighborsClassifier**
- **ROC-AUC:** 0.9655 | **F1:** 0.9942
- **Problema:** Performance inferior en ROC-AUC
- **Causa:** Dataset con patrones no locales
- **Trade-off:** Entrenamiento instant√°neo (0.00s) pero menor calidad

---

## üé® Visualizaciones Generadas

### 1. **model_comparison.png** (932 KB)
Incluye 4 subplots:
- **M√©tricas de clasificaci√≥n:** Barras comparativas de Accuracy, Precision, Recall, F1
- **ROC-AUC Scores:** Todos los modelos ordenados
- **F1-Score vs Training Time:** Trade-off performance/velocidad (escala log)
- **Heatmap de m√©tricas:** Patr√≥n de colores para identificaci√≥n r√°pida

### 2. **roc_curves.png** (300 KB)
- Curvas ROC de los Top 5 modelos
- Estilos de l√≠nea variados (s√≥lida, guiones, punto-gui√≥n)
- Marcadores distintivos para diferenciaci√≥n
- Nota: Curvas superpuestas indican performance perfecta id√©ntica

### 3. **confusion_matrices.png** (185 KB)
- Matrices de confusi√≥n de los Top 4 modelos
- Valores anotados en cada celda
- Escala de colores para interpretaci√≥n visual

---

## üî¨ Feature Engineering - Impacto

### Features Creadas: 35 total

#### **Date Features (4)**
- `mes_prestamo`, `dia_semana`, `trimestre`, `dias_desde_epoca`
- **Impacto:** Captura estacionalidad y tendencias temporales

#### **Financial Features (10)**
Las m√°s importantes:
1. **`ratio_cuota_salario`** - Compromiso de ingreso del cliente
2. **`ratio_deuda_ingreso`** - Nivel de endeudamiento total
3. **`ingreso_disponible`** - Capacidad de pago real
4. **`nivel_endeudamiento`** - √çndice de deuda consolidada
5. **`tiene_mora`** / **`tiene_codeudor_mora`** - Flags de riesgo

**Resultado:** Estas 10 features financieras aportan la mayor capacidad predictiva.

---

## üìä M√©tricas del Dataset

### Distribuci√≥n de Clases
| Clase | Registros | % |
|-------|-----------|---|
| **1 (Pago a tiempo)** | 10,253 | 95.3% |
| **0 (Pago atrasado)** | 510 | 4.7% |

**Ratio de desbalanceo:** ~1:20

### Estratificaci√≥n en Train/Test
- **Train:** 8,610 registros (80%)
- **Test:** 2,153 registros (20%)
- **Estratificaci√≥n:** Aplicada para mantener proporci√≥n

### Manejo del Desbalanceo
```python
class_weight='balanced'  # Aplicado a todos los modelos
```
- Penaliza errores en clase minoritaria
- Evita bias hacia clase mayoritaria

---

## ‚ö†Ô∏è Advertencias y Consideraciones

### 1. **Data Leakage Potencial**
- Variable `puntaje` tiene correlaci√≥n 0.923 con target
- **Acci√≥n:** Revisar si es informaci√≥n del futuro
- **Mitigaci√≥n:** Re-entrenar sin `puntaje` si es necesario

### 2. **Performance Perfecta Sospechosa**
- 5 modelos con ROC-AUC = 1.0000
- **Posible causa:** Dataset muy separable o leakage
- **Acci√≥n:** Validar con datos de producci√≥n reales

### 3. **Overfitting en DecisionTree**
- √Årbol sin restricciones de profundidad
- **Riesgo:** Memorizaci√≥n del training set
- **Mitigaci√≥n:** Probar con `max_depth=10` en producci√≥n

---

## üöÄ Recomendaciones Finales

### Para Deployment en Producci√≥n

#### **Opci√≥n 1: DecisionTreeClassifier** (Recomendada)
```python
‚úÖ Usar si: Latencia < 50ms es cr√≠tica
‚úÖ Ventaja: Velocidad + performance perfecta
‚ö†Ô∏è Riesgo: Revisar overfitting con datos nuevos
```

#### **Opci√≥n 2: RandomForestClassifier** (Alternativa segura)
```python
‚úÖ Usar si: Robustez > Velocidad
‚úÖ Ventaja: Ensemble m√°s estable
‚ö†Ô∏è Trade-off: 5x m√°s lento (0.21s vs 0.04s)
```

#### **Opci√≥n 3: AdaBoostClassifier** (Ultra-r√°pida)
```python
‚úÖ Usar si: Latencia < 20ms es mandatorio
‚úÖ Ventaja: Modelo m√°s r√°pido (0.02s)
‚ö†Ô∏è Riesgo: Menos robusto que ensemble completo
```

### Para Investigaci√≥n Adicional

1. **Feature Importance Analysis**
   - Identificar las 10 features m√°s importantes
   - Eliminar features redundantes
   - Re-entrenar con subset optimizado

2. **Validaci√≥n Cruzada**
   - Aplicar K-Fold (k=5) para validaci√≥n
   - Confirmar que performance se mantiene

3. **Pruebas con Datos Nuevos**
   - Validar en datos de meses futuros
   - Monitorear drift en distribuciones

---

## üìÅ Archivos de Salida

Todos los resultados se encuentran en `results/`:

```
results/
‚îú‚îÄ‚îÄ model_comparison.png         # Comparaci√≥n visual completa
‚îú‚îÄ‚îÄ roc_curves.png               # Curvas ROC Top 5
‚îú‚îÄ‚îÄ confusion_matrices.png       # Matrices Top 4
‚îú‚îÄ‚îÄ evaluation_report.txt        # Reporte textual detallado
‚îî‚îÄ‚îÄ model_results.csv            # Tabla exportable
```

---

## üîÑ Reproducibilidad

Para reproducir estos resultados:

```bash
# 1. Instalar dependencias exactas
pip install -r requirements.txt

# 2. Ejecutar pipeline con seed fijo (42)
python mlops_pipeline/run_pipeline.py

# 3. Verificar salida en results/
```

**Seed fijo:** `random_state=42` en todos los modelos y splits

---

**üìä An√°lisis completado exitosamente**

**11 modelos** | **35 features** | **10,763 registros** | **Performance perfecta**

---

